---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: user-manifests-bootstrapper
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: user-manifests-bootstrapper
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: edit
subjects:
  - kind: ServiceAccount
    name: user-manifests-bootstrapper
---
apiVersion: v1
kind: Pod
metadata:
  name: manifests-bootstrapper
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: dedicated
            operator: In
            values:
            - master-{{ .ClusterID }}
  tolerations:
    - key: "dedicated"
      operator: "Equal"
      value: "master-{{ .ClusterID }}"
      effect: NoSchedule
    - key: "multi-az-worker"
      operator: "Equal"
      value: "true"
      effect: NoSchedule
  initContainers:
    - image: {{ .ReleaseImage }}
      imagePullPolicy: IfNotPresent
      name: cluster-version-operator
{{- if .ClusterVersionOperatorSecurityContext }}
{{- $securityContext := .ClusterVersionOperatorSecurityContext }}
      securityContext:
        runAsUser: {{ $securityContext.RunAsUser }}
{{- end }}
      workingDir: /tmp
      command:
        - /bin/bash
      args:
        - -c
        - |-
          cd /tmp
          mkdir -p output/manifests output/bootstrap
          /usr/bin/cluster-version-operator render --output-dir /tmp/output --release-image {{ .ReleaseImage }}
          # Exclude the CVO deployment manifest
          rm /tmp/output/manifests/0000_00_cluster-version-operator*deployment.yaml
          cp /tmp/output/manifests/* /work
          # Add machineconfig CRDs to prevent upgrade getting stuck
          cp /release-manifests/*machine-config-operator*machineconfig*.crd.yaml /work
      volumeMounts:
        - mountPath: /work
          name: work
  containers:
    - image: {{ imageFor "cli" }}
      imagePullPolicy: IfNotPresent
      name: bootstrapper
{{- if .ManifestBootstrapperSecurityContext }}
{{- $securityContext := .ManifestBootstrapperSecurityContext }}
      securityContext:
        runAsUser: {{ $securityContext.RunAsUser }}
{{- end }}
      workingDir: /work
      command:
        - /bin/bash
      args:
        - -c
        - |-
          #!/bin/bash
          set -eu
          for name in $(oc get cm | grep '^user-manifest-' | awk '{ print $1 }'); do
             oc get cm ${name} -o jsonpath='{ .data.data }' > "${name}.yaml"
          done
          oc get secret user-manifest-openshift-browser-client -ojsonpath='{ .data.data }' | base64 -d > "user-manifest-openshift-browser-client.yaml"
          export KUBECONFIG=/etc/openshift/kubeconfig
          oc apply -f $(pwd)
          # Replace the global certs configmap here because it's too large to oc apply
          oc create configmap -n openshift-controller-manager openshift-global-ca --from-file ca-bundle.crt=/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem --dry-run=client -o yaml > /tmp/openshift-global-ca
          oc replace -n openshift-controller-manager -f /tmp/openshift-global-ca --force
          # Create the ClusterVersion resource if it doesn't already exist
          oc get ClusterVersion version
          CLUSTER_VERSION_NOT_FOUND=$?
          if [[ $CLUSTER_VERSION_NOT_FOUND -eq 1 ]]; then
             apt install uuid-runtime
             clusterUUID=$(uuidgen)
             oc create -f <<EOF
                apiVersion: config.openshift.io/v1
                kind: ClusterVersion
                metadata:
                   name: version
                spec:
                   clusterID: $clusterUUID
             EOF
          fi
      resources:
        requests:
          memory: "75Mi"
          cpu: "10m"
      volumeMounts:
        - mountPath: /etc/openshift
          name: kubeconfig
          readOnly: true
        - mountPath: /work
          name: work
  restartPolicy: OnFailure
  serviceAccountName: user-manifests-bootstrapper
  volumes:
    - name: kubeconfig
      secret:
        secretName: service-network-admin-kubeconfig
        defaultMode: 0640
    - name: work
      emptyDir: {}
